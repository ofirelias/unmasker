{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8752c-446d-4e05-ad53-8546a9c13e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1780 masked images and 1780 unmasked images.\n",
      "Epoch [0/50] Batch 0/112 D Loss: 0.7234, G Loss: 74.1440\n",
      "Epoch [0/50] Batch 100/112 D Loss: 0.5183, G Loss: 11.6424\n",
      "Epoch [1/50] Batch 0/112 D Loss: 0.4288, G Loss: 11.4126\n",
      "Epoch [1/50] Batch 100/112 D Loss: 0.3030, G Loss: 10.5109\n",
      "Epoch [2/50] Batch 0/112 D Loss: 0.1533, G Loss: 9.6724\n",
      "Epoch [2/50] Batch 100/112 D Loss: 0.1510, G Loss: 9.7579\n",
      "Epoch [3/50] Batch 0/112 D Loss: 0.2139, G Loss: 9.7484\n",
      "Epoch [3/50] Batch 100/112 D Loss: 0.0123, G Loss: 11.9706\n",
      "Epoch [4/50] Batch 0/112 D Loss: 0.0191, G Loss: 12.2753\n",
      "Epoch [4/50] Batch 100/112 D Loss: 0.0053, G Loss: 12.4170\n",
      "Epoch [5/50] Batch 0/112 D Loss: 0.0082, G Loss: 11.4801\n",
      "Epoch [5/50] Batch 100/112 D Loss: 0.0074, G Loss: 12.6663\n",
      "Epoch [6/50] Batch 0/112 D Loss: 0.0082, G Loss: 14.4509\n",
      "Epoch [6/50] Batch 100/112 D Loss: 1.3093, G Loss: 6.5933\n",
      "Epoch [7/50] Batch 0/112 D Loss: 0.6324, G Loss: 6.8912\n",
      "Epoch [7/50] Batch 100/112 D Loss: 0.0136, G Loss: 10.8017\n",
      "Epoch [8/50] Batch 0/112 D Loss: 0.0120, G Loss: 10.0896\n",
      "Epoch [8/50] Batch 100/112 D Loss: 0.0105, G Loss: 10.6189\n",
      "Epoch [9/50] Batch 0/112 D Loss: 0.0088, G Loss: 10.0760\n",
      "Epoch [9/50] Batch 100/112 D Loss: 0.0067, G Loss: 10.7055\n",
      "Epoch [10/50] Batch 0/112 D Loss: 0.0037, G Loss: 11.8715\n",
      "Epoch [10/50] Batch 100/112 D Loss: 0.0026, G Loss: 11.4127\n",
      "Epoch [11/50] Batch 0/112 D Loss: 0.0042, G Loss: 10.6045\n",
      "Epoch [11/50] Batch 100/112 D Loss: 0.1063, G Loss: 9.6566\n",
      "Epoch [12/50] Batch 0/112 D Loss: 0.0105, G Loss: 11.1326\n",
      "Epoch [12/50] Batch 100/112 D Loss: 0.0039, G Loss: 13.8510\n",
      "Epoch [13/50] Batch 0/112 D Loss: 0.0073, G Loss: 9.4960\n",
      "Epoch [13/50] Batch 100/112 D Loss: 0.0050, G Loss: 15.0011\n",
      "Epoch [14/50] Batch 0/112 D Loss: 0.0034, G Loss: 15.3416\n",
      "Epoch [14/50] Batch 100/112 D Loss: 0.0016, G Loss: 12.7133\n",
      "Epoch [15/50] Batch 0/112 D Loss: 0.0083, G Loss: 12.4695\n",
      "Epoch [15/50] Batch 100/112 D Loss: 0.6731, G Loss: 4.8392\n",
      "Epoch [16/50] Batch 0/112 D Loss: 0.4651, G Loss: 6.7003\n",
      "Epoch [16/50] Batch 100/112 D Loss: 0.0916, G Loss: 7.8137\n",
      "Epoch [17/50] Batch 0/112 D Loss: 0.0249, G Loss: 10.6476\n",
      "Epoch [17/50] Batch 100/112 D Loss: 0.0424, G Loss: 8.7256\n",
      "Epoch [18/50] Batch 0/112 D Loss: 0.0293, G Loss: 9.7030\n",
      "Epoch [18/50] Batch 100/112 D Loss: 0.0113, G Loss: 13.5772\n",
      "Epoch [19/50] Batch 0/112 D Loss: 0.2282, G Loss: 7.8342\n",
      "Epoch [19/50] Batch 100/112 D Loss: 0.0114, G Loss: 13.7607\n",
      "Epoch [20/50] Batch 0/112 D Loss: 0.0075, G Loss: 10.2825\n",
      "Epoch [20/50] Batch 100/112 D Loss: 0.0055, G Loss: 13.4582\n",
      "Epoch [21/50] Batch 0/112 D Loss: 0.0022, G Loss: 11.6671\n",
      "Epoch [21/50] Batch 100/112 D Loss: 0.0096, G Loss: 9.4624\n",
      "Epoch [22/50] Batch 0/112 D Loss: 0.0042, G Loss: 10.4861\n",
      "Epoch [22/50] Batch 100/112 D Loss: 0.7761, G Loss: 4.7257\n",
      "Epoch [23/50] Batch 0/112 D Loss: 1.0201, G Loss: 6.0435\n",
      "Epoch [23/50] Batch 100/112 D Loss: 0.1243, G Loss: 7.5435\n",
      "Epoch [24/50] Batch 0/112 D Loss: 0.5946, G Loss: 10.7552\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Define the U-Net Generator\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        # Define the layers for U-Net architecture\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Up-sampling layers\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.up3 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through down-sampling layers\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        \n",
    "        # Forward pass through up-sampling layers with skip connections\n",
    "        x = self.up1(x3)\n",
    "        x = self.up2(x + x2)  # Skip connection\n",
    "        x = self.up3(x + x1)  # Skip connection\n",
    "        return torch.tanh(x)  # Output should be in the range [-1, 1]\n",
    "\n",
    "# Define the PatchGAN Discriminator\n",
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "        # Define the layers for PatchGAN\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Concatenate the input and generated/real images along the channel dimension\n",
    "        input = torch.cat([x, y], dim=1)\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        return x\n",
    "\n",
    "# Define loss functions\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()  # Binary Cross Entropy for GANs\n",
    "l1_loss = nn.L1Loss()  # L1 loss for image reconstruction\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "generator = UNetGenerator().to(device)\n",
    "discriminator = PatchGANDiscriminator().to(device)\n",
    "\n",
    "# Define optimizers\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Define the training loop\n",
    "def train(dataloader, epochs, save_interval=10):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (masked, unmasked) in enumerate(dataloader):\n",
    "            masked, unmasked = masked.to(device), unmasked.to(device)\n",
    "\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # Real images\n",
    "            real_validity = discriminator(masked, unmasked)\n",
    "            real_loss = adversarial_loss(real_validity, torch.ones_like(real_validity))\n",
    "\n",
    "            # Fake images\n",
    "            fake_unmasked = generator(masked)\n",
    "            fake_validity = discriminator(masked, fake_unmasked.detach())\n",
    "            fake_loss = adversarial_loss(fake_validity, torch.zeros_like(fake_validity))\n",
    "\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # -----------------\n",
    "            # Train Generator\n",
    "            # -----------------\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            # Generate images and calculate generator loss\n",
    "            fake_unmasked = generator(masked)\n",
    "            fake_validity = discriminator(masked, fake_unmasked)\n",
    "            g_adv_loss = adversarial_loss(fake_validity, torch.ones_like(fake_validity))\n",
    "\n",
    "            # L1 loss\n",
    "            g_l1_loss = l1_loss(fake_unmasked, unmasked)\n",
    "\n",
    "            # Total generator loss\n",
    "            g_loss = g_adv_loss + 100 * g_l1_loss\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            if i % save_interval == 0:\n",
    "                print(f\"Epoch [{epoch}/{epochs}] Batch {i}/{len(dataloader)} \"\n",
    "                      f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "# Define the image preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = \"MaskTheFace/faces\"\n",
    "masked_path = os.path.join(dataset_path, \"Celebrity Faces Dataset_masked\")\n",
    "unmasked_path = os.path.join(dataset_path, \"Celebrity Faces Dataset\")\n",
    "\n",
    "class MaskedFaceDataset(Dataset):\n",
    "    def __init__(self, masked_dir, unmasked_dir, transform=None):\n",
    "        self.masked_dir = masked_dir\n",
    "        self.unmasked_dir = unmasked_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Recursively find all image paths in subdirectories\n",
    "        self.masked_images, self.unmasked_images = self._get_paired_image_paths()\n",
    "\n",
    "        print(f\"Found {len(self.masked_images)} masked images and {len(self.unmasked_images)} unmasked images.\")\n",
    "        assert len(self.masked_images) == len(self.unmasked_images), \"Mismatch between masked and unmasked images count!\"\n",
    "\n",
    "    def _get_paired_image_paths(self):\n",
    "        # Recursively find all image files in each directory\n",
    "        masked_files = []\n",
    "        unmasked_files = []\n",
    "\n",
    "        for root, _, files in os.walk(self.masked_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')) and not file.startswith('.'):\n",
    "                    masked_files.append(os.path.join(root, file))\n",
    "\n",
    "        for root, _, files in os.walk(self.unmasked_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')) and not file.startswith('.'):\n",
    "                    unmasked_files.append(os.path.join(root, file))\n",
    "\n",
    "        # Find matching pairs based on the filenames without the '_surgical' suffix\n",
    "        paired_masked_paths = []\n",
    "        paired_unmasked_paths = []\n",
    "\n",
    "        for masked_file in masked_files:\n",
    "            base_name = os.path.basename(masked_file).replace('_surgical', '')\n",
    "\n",
    "            # Look for a matching unmasked file by the base name\n",
    "            matching_unmasked_file = next((uf for uf in unmasked_files if os.path.basename(uf) == base_name), None)\n",
    "\n",
    "            if matching_unmasked_file:\n",
    "                paired_masked_paths.append(masked_file)\n",
    "                paired_unmasked_paths.append(matching_unmasked_file)\n",
    "\n",
    "        return sorted(paired_masked_paths), sorted(paired_unmasked_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.masked_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        masked_image_path = self.masked_images[idx]\n",
    "        unmasked_image_path = self.unmasked_images[idx]\n",
    "\n",
    "        # Read the images using PIL for better compatibility\n",
    "        masked_image = Image.open(masked_image_path).convert(\"RGB\")\n",
    "        unmasked_image = Image.open(unmasked_image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            masked_image = self.transform(masked_image)\n",
    "            unmasked_image = self.transform(unmasked_image)\n",
    "\n",
    "        return masked_image, unmasked_image\n",
    "\n",
    "\n",
    "# Create dataloader\n",
    "dataset = MaskedFaceDataset(masked_path, unmasked_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Train the GAN\n",
    "train(dataloader, epochs=50, save_interval=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a27c1-d034-4349-a1ac-c66e46888765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
