{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8752c-446d-4e05-ad53-8546a9c13e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1780 masked images and 1780 unmasked images.\n",
      "Epoch [0/50] Batch 0/112 D Loss: 0.7136, G Loss: 76.4407\n",
      "Epoch [0/50] Batch 100/112 D Loss: 0.3880, G Loss: 13.1705\n",
      "Epoch [1/50] Batch 0/112 D Loss: 0.2853, G Loss: 12.0404\n",
      "Epoch [1/50] Batch 100/112 D Loss: 0.0296, G Loss: 11.3488\n",
      "Epoch [2/50] Batch 0/112 D Loss: 0.0458, G Loss: 11.6293\n",
      "Epoch [2/50] Batch 100/112 D Loss: 0.0878, G Loss: 9.3152\n",
      "Epoch [3/50] Batch 0/112 D Loss: 0.1224, G Loss: 12.4662\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the U-Net Generator\n",
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        # Define the layers for U-Net architecture\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Up-sampling layers\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.up3 = nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through down-sampling layers\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        \n",
    "        # Forward pass through up-sampling layers with skip connections\n",
    "        x = self.up1(x3)\n",
    "        x = self.up2(x + x2)  # Skip connection\n",
    "        x = self.up3(x + x1)  # Skip connection\n",
    "        return torch.tanh(x)  # Output should be in the range [-1, 1]\n",
    "\n",
    "# Define the PatchGAN Discriminator\n",
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "        # Define the layers for PatchGAN\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Concatenate the input and generated/real images along the channel dimension\n",
    "        input = torch.cat([x, y], dim=1)\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        return x\n",
    "\n",
    "# Define loss functions\n",
    "adversarial_loss = nn.BCEWithLogitsLoss()  # Binary Cross Entropy for GANs\n",
    "l1_loss = nn.L1Loss()  # L1 loss for image reconstruction\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "generator = UNetGenerator().to(device)\n",
    "discriminator = PatchGANDiscriminator().to(device)\n",
    "\n",
    "# Define optimizers\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Define the training loop\n",
    "def train(dataloader, epochs, save_interval=10):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (masked, unmasked) in enumerate(dataloader):\n",
    "            masked, unmasked = masked.to(device), unmasked.to(device)\n",
    "\n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            # Real images\n",
    "            real_validity = discriminator(masked, unmasked)\n",
    "            real_loss = adversarial_loss(real_validity, torch.ones_like(real_validity))\n",
    "\n",
    "            # Fake images\n",
    "            fake_unmasked = generator(masked)\n",
    "            fake_validity = discriminator(masked, fake_unmasked.detach())\n",
    "            fake_loss = adversarial_loss(fake_validity, torch.zeros_like(fake_validity))\n",
    "\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # -----------------\n",
    "            # Train Generator\n",
    "            # -----------------\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            # Generate images and calculate generator loss\n",
    "            fake_unmasked = generator(masked)\n",
    "            fake_validity = discriminator(masked, fake_unmasked)\n",
    "            g_adv_loss = adversarial_loss(fake_validity, torch.ones_like(fake_validity))\n",
    "\n",
    "            # L1 loss\n",
    "            g_l1_loss = l1_loss(fake_unmasked, unmasked)\n",
    "\n",
    "            # Total generator loss\n",
    "            g_loss = g_adv_loss + 100 * g_l1_loss\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            if i % save_interval == 0:\n",
    "                print(f\"Epoch [{epoch}/{epochs}] Batch {i}/{len(dataloader)} \"\n",
    "                      f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "# Define the image preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = \"MaskTheFace/faces\"\n",
    "masked_path = os.path.join(dataset_path, \"Celebrity Faces Dataset_masked\")\n",
    "unmasked_path = os.path.join(dataset_path, \"Celebrity Faces Dataset\")\n",
    "\n",
    "class MaskedFaceDataset(Dataset):\n",
    "    def __init__(self, masked_dir, unmasked_dir, transform=None):\n",
    "        self.masked_dir = masked_dir\n",
    "        self.unmasked_dir = unmasked_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Recursively find all image paths in subdirectories\n",
    "        self.masked_images, self.unmasked_images = self._get_paired_image_paths()\n",
    "\n",
    "        print(f\"Found {len(self.masked_images)} masked images and {len(self.unmasked_images)} unmasked images.\")\n",
    "        assert len(self.masked_images) == len(self.unmasked_images), \"Mismatch between masked and unmasked images count!\"\n",
    "\n",
    "    def _get_paired_image_paths(self):\n",
    "        # Recursively find all image files in each directory\n",
    "        masked_files = []\n",
    "        unmasked_files = []\n",
    "\n",
    "        for root, _, files in os.walk(self.masked_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')) and not file.startswith('.'):\n",
    "                    masked_files.append(os.path.join(root, file))\n",
    "\n",
    "        for root, _, files in os.walk(self.unmasked_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')) and not file.startswith('.'):\n",
    "                    unmasked_files.append(os.path.join(root, file))\n",
    "\n",
    "        # Find matching pairs based on the filenames without the '_surgical' suffix\n",
    "        paired_masked_paths = []\n",
    "        paired_unmasked_paths = []\n",
    "\n",
    "        for masked_file in masked_files:\n",
    "            base_name = os.path.basename(masked_file).replace('_surgical', '')\n",
    "\n",
    "            # Look for a matching unmasked file by the base name\n",
    "            matching_unmasked_file = next((uf for uf in unmasked_files if os.path.basename(uf) == base_name), None)\n",
    "\n",
    "            if matching_unmasked_file:\n",
    "                paired_masked_paths.append(masked_file)\n",
    "                paired_unmasked_paths.append(matching_unmasked_file)\n",
    "\n",
    "        return sorted(paired_masked_paths), sorted(paired_unmasked_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.masked_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        masked_image_path = self.masked_images[idx]\n",
    "        unmasked_image_path = self.unmasked_images[idx]\n",
    "\n",
    "        # Read the images using PIL for better compatibility\n",
    "        masked_image = Image.open(masked_image_path).convert(\"RGB\")\n",
    "        unmasked_image = Image.open(unmasked_image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            masked_image = self.transform(masked_image)\n",
    "            unmasked_image = self.transform(unmasked_image)\n",
    "\n",
    "        return masked_image, unmasked_image\n",
    "\n",
    "\n",
    "# Create dataloader\n",
    "dataset = MaskedFaceDataset(masked_path, unmasked_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Train the GAN\n",
    "train(dataloader, epochs=50, save_interval=100)\n",
    "\n",
    "# Save the generator model after training\n",
    "torch.save(generator.state_dict(), 'unmask_generator.pth')\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a27c1-d034-4349-a1ac-c66e46888765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary modules\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the model (use same definition as during training)\n",
    "generator = UNetGenerator().to(device)\n",
    "generator.load_state_dict(torch.load('unmask_generator.pth', map_location=device))\n",
    "generator.eval()\n",
    "\n",
    "# Image preprocessing pipeline (match training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load a masked image\n",
    "masked_img = Image.open(\"path/to/masked_image.jpg\").convert(\"RGB\")\n",
    "input_tensor = transform(masked_img).unsqueeze(0).to(device)\n",
    "\n",
    "# Generate the unmasked face\n",
    "with torch.no_grad():\n",
    "    output_tensor = generator(input_tensor).cpu().squeeze(0)\n",
    "    output_img = transforms.ToPILImage()(0.5 * output_tensor + 0.5)  # De-normalize from [-1,1] to [0,1]\n",
    "\n",
    "# Display results\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(masked_img)\n",
    "ax[0].set_title(\"Masked Input\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(output_img)\n",
    "ax[1].set_title(\"Unmasked Output\")\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
